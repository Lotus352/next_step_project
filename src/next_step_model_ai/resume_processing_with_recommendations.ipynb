{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a8934336",
   "metadata": {},
   "source": [
    "# **Fully Optimized Resume Processing and Segmentation**\n",
    "This notebook extracts, cleans, anonymizes, and segments resume content from various file formats (PDF, DOCX, TXT). It ensures accurate section detection and structured output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dc9bb058",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import re\n",
    "import pdfminer.high_level\n",
    "from docx import Document\n",
    "from collections import defaultdict\n",
    "\n",
    "# Define section headers for resume segmentation\n",
    "SECTION_HEADERS = {\n",
    "    \"contact\": [\"contact\", \"personal details\", \"info\", \"email\", \"phone\", \"location\"],\n",
    "    \"summary\": [\"summary\", \"profile\", \"about me\", \"objective\"],\n",
    "    \"experience\": [\"experience\", \"work experience\", \"employment\", \"internships\"],\n",
    "    \"education\": [\"education\", \"academic background\"],\n",
    "    \"skills\": [\"skills\", \"technical skills\", \"core competencies\", \"language\"],\n",
    "    \"certifications\": [\"certifications\", \"licenses\", \"certificates\"],\n",
    "    \"projects\": [\"projects\", \"portfolio\"],\n",
    "    \"languages\": [\"languages\", \"spoken languages\"],\n",
    "    \"miscellaneous\": [\"hobbies\", \"volunteer work\", \"interests\"]\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "514dec6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def extract_text_from_pdf(pdf_path):\n",
    "    \"\"\"Extract text from a PDF file.\"\"\"\n",
    "    try:\n",
    "        text = pdfminer.high_level.extract_text(pdf_path)\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting PDF text: {str(e)}\"\n",
    "\n",
    "def extract_text_from_docx(docx_path):\n",
    "    \"\"\"Extract text from a DOCX file.\"\"\"\n",
    "    try:\n",
    "        doc = Document(docx_path)\n",
    "        text = \"\\n\".join([para.text for para in doc.paragraphs])\n",
    "        return text.strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting DOCX text: {str(e)}\"\n",
    "\n",
    "def extract_text_from_txt(txt_path):\n",
    "    \"\"\"Extract text from a TXT file.\"\"\"\n",
    "    try:\n",
    "        with open(txt_path, \"r\", encoding=\"utf-8\") as f:\n",
    "            return f.read().strip()\n",
    "    except Exception as e:\n",
    "        return f\"Error extracting TXT text: {str(e)}\"\n",
    "\n",
    "def extract_text_from_cv(file_path):\n",
    "    \"\"\"Identify the file format and extract text accordingly.\"\"\"\n",
    "    if not os.path.exists(file_path):\n",
    "        return \"File not found!\"\n",
    "\n",
    "    ext = os.path.splitext(file_path)[1].lower()\n",
    "    if ext == \".pdf\":\n",
    "        return extract_text_from_pdf(file_path)\n",
    "    elif ext == \".docx\":\n",
    "        return extract_text_from_docx(file_path)\n",
    "    elif ext == \".txt\":\n",
    "        return extract_text_from_txt(file_path)\n",
    "    else:\n",
    "        return \"Unsupported file format! Please use PDF, DOCX, or TXT.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1a1e7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Fix extracted text formatting issues before segmentation.\"\"\"\n",
    "    text = re.sub(r\"\\s+\", \" \", text)  # Remove extra spaces\n",
    "    text = re.sub(r\"(?<=\\b[A-Z])\\s(?=[A-Z]+\\b)\", \"\", text)  # Remove spaces between capitalized words\n",
    "    text = re.sub(r\"\\s([,.])\", r\"\\1\", text)  # Fix spaces before punctuation\n",
    "    return text\n",
    "\n",
    "def remove_sensitive_info(text):\n",
    "    \"\"\"Removes sensitive information such as emails, phone numbers, and URLs.\"\"\"\n",
    "    text = re.sub(r\"\\b[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\.[A-Z|a-z]{2,}\\b\", \"[EMAIL]\", text)\n",
    "    text = re.sub(r\"\\b(\\+?\\d{1,3}[-.\\s]?)?\\(?\\d{2,4}\\)?[-.\\s]?\\d{2,4}[-.\\s]?\\d{2,9}\\b\", \"[PHONE]\", text)\n",
    "    text = re.sub(r\"http[s]?://\\S+\", \"[URL]\", text)\n",
    "    return text\n",
    "\n",
    "def clean_and_normalize_text(text):\n",
    "    \"\"\"Basic text cleaning: remove unnecessary spaces and normalize text.\"\"\"\n",
    "    text = re.sub(r\"\\s+\", \" \", text).strip()\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a40f3f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def segment_resume_final(text):\n",
    "    \"\"\"Final optimized segmentation function ensuring accurate section detection.\"\"\"\n",
    "    text = preprocess_text(clean_and_normalize_text(text))\n",
    "    sections = defaultdict(str)\n",
    "    current_section = \"summary\"  # Default section for initial text\n",
    "\n",
    "    # Ensure section headers are properly formatted and separated\n",
    "    for section, keywords in SECTION_HEADERS.items():\n",
    "        for kw in keywords:\n",
    "            text = re.sub(rf\"(\\s*{kw}\\s*)\", r\"\\n\\1\\n\", text, flags=re.IGNORECASE)\n",
    "\n",
    "    # Split text into lines\n",
    "    lines = text.split(\"\\n\")\n",
    "    found_first_section = False\n",
    "\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue  # Skip empty lines\n",
    "\n",
    "        # Identify section headers\n",
    "        found_section = None\n",
    "        for section, keywords in SECTION_HEADERS.items():\n",
    "            if any(re.match(rf\"^\\s*{kw}\\s*$\", line, re.IGNORECASE) for kw in keywords):\n",
    "                found_section = section\n",
    "                found_first_section = True\n",
    "                break\n",
    "\n",
    "        if found_section:\n",
    "            current_section = found_section\n",
    "            sections[current_section] = \"\"\n",
    "        else:\n",
    "            if not found_first_section:\n",
    "                sections[\"summary\"] += line + \" \"\n",
    "            elif \"@\" in line or \"Phone\" in line or \"Location\" in line:\n",
    "                sections[\"contact\"] += line + \" \"\n",
    "            else:\n",
    "                sections[current_section] += line + \" \"\n",
    "\n",
    "    return sections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "896309b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def process_resume(file_path):\n",
    "    \"\"\"Extracts, cleans, anonymizes, and segments resume from a given file.\"\"\"\n",
    "    extracted_text = extract_text_from_cv(file_path)\n",
    "    clean_text = remove_sensitive_info(extracted_text)\n",
    "    structured_resume = segment_resume_final(clean_text)\n",
    "    return structured_resume\n",
    "\n",
    "def display_segmented_resume(resume_data):\n",
    "    \"\"\"Displays segmented resume data in a readable format.\"\"\"\n",
    "    print(\"\\n======================= SEGMENTED RESUME =======================\")\n",
    "    for section, content in resume_data.items():\n",
    "        if content.strip():\n",
    "            print(f\"\\n=== {section.upper()} ===\\n{content.strip()}\")\n",
    "    print(\"\\n================================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "caa146f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================= SEGMENTED RESUME =======================\n",
      "\n",
      "=== SUMMARY ===\n",
      "I am a passionate developer with\n",
      "\n",
      "=== EXPERIENCE ===\n",
      "INTERN • FPT Software Da Nang. June 2023 - August 2023 I participated in developing a Java and Spring Boot-based sales management application using the MVC architecture. Followed the company’s rules, coding standards, and version control procedures to keep the project consistent. Improved teamwork and communication through regular feedback sessions, code reviews, and problem-solving discussions.\n",
      "\n",
      "=== SKILLS ===\n",
      "s: Java, C#, JavaScript. Frameworks: Java Spring,.NET Framework, Express. Web Development: HTML, CSS, JavaScript. Databases: MySQL, SQL Server, MongoDB. Tools & Platforms: Github, Swagger, Postman, Trello, Jira. English: Intermediate level in listening and translation. TOEIC: 650\n",
      "\n",
      "=== CONTACT ===\n",
      "rmation Systems\n",
      "\n",
      "=== EDUCATION ===\n",
      "Danang University of Science and Technology. 2020 - 2025 Bachelor of Engineering in\n",
      "\n",
      "=== PROJECTS ===\n",
      "E-Commerce Web Application The E-Commerce project is a web-based application developed to facilitate online shopping and business management. The project uses the client-server model with Java Spring for the backend and ReactJS for the frontend. The application allows businesses to register, manage their products, and sell them online. It also integrates online account payments and MoMo QR code payments. Technologies Used: Java Spring, ReactJS. Total Members: 3. My Role: Backend Developer. Github : [URL] Novel Recommendation The Novel Recommendation is a web-based application developed to manage and suggest novels to users. The project uses the client-server model with Express and MongoDB for the backend, and Flask to build the recommendation API. The application allows users to register, read novels, and manage their favorite novels. The recommendation system uses deep learning for both recommendation and search functionalities. Technologies Used: Express, Flask, ReactJS. Total Members: 3. My Role: Backend Developer and Recommendation model creator. Github : [URL]\n",
      "\n",
      "================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Test with uploaded sample CV\n",
    "file_path = \"sample_cv.pdf\"  # Change this if needed\n",
    "resume_data = process_resume(file_path)\n",
    "display_segmented_resume(resume_data)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
